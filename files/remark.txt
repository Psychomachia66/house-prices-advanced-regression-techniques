线性回归 11-14-18-50
0.13

RF-v0.1 11-13-22-47
0.14
分析：
1. 对数变换（log1p）极大提升了线性模型的适配性
原始房价分布：严重右偏（少量豪宅拉高均值）
对数变换后：近似正态 → 线性回归的核心假设（误差正态性）被满足
随机森林：对标签分布不敏感，但 无法利用线性关系

结论：log(SalePrice) 与特征之间更接近 线性关系 → 线性回归天然占优。
2. 特征工程对线性模型“友好”
处理,对线性模型,对树模型
One-Hot 编码,完美适配,冗余特征多
标准化（StandardScaler）,必须（否则系数不可比）,无用（树模型尺度不变）
"缺失值填补为 ""Missing""",新类别有意义,可能被忽略
你 标准化了数值特征 + One-Hot 了所有类别 → 线性回归得到 干净、可解释的线性空间，而树模型反而被 高维稀疏特征 干扰。
3. 高维稀疏特征（One-Hot）对随机森林是“诅咒”
43 个类别列 → 编码后 数百维稀疏向量
每棵树在 高维稀疏空间 中分裂时：
有效特征被“稀释”
容易过拟合噪声
特征重要性分散
线性回归：所有特征同等对待，L2 正则化抑制噪声
随机森林：分裂点选择困难，性能下降
4. 正则化（ElasticNet）让线性回归更鲁棒